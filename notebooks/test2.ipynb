{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "def preprocess_images_folder(folder_path, resolution=(32, 32)):\n",
    "    tensor_list = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            # Preprocess the image and append the tensor to the list\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            tensor = preprocess_image(image_path,\n",
    "                                      normalize=True,\n",
    "                                      keep_alpha=False,\n",
    "                                      resolution=resolution)\n",
    "            tensor_list.append(tensor)\n",
    "    # Stack the list of tensors into a single tensor\n",
    "    tensor_stack = torch.stack(tensor_list)\n",
    "    tensor_stack = tensor_stack.squeeze()  # remove the singleton dimension\n",
    "    return tensor_stack\n",
    "\n",
    "def preprocess_image(image_path,\n",
    "                     normalize=True,\n",
    "                     keep_alpha=False,\n",
    "                     resolution=(32, 32)):\n",
    "    # Load the image using PIL\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    # Check if the image has an alpha channel\n",
    "    has_alpha = image.mode.endswith('A')\n",
    "\n",
    "    # Convert the image to RGB if it has an alpha channel and we're not keeping it\n",
    "    if has_alpha and not keep_alpha:\n",
    "        image = image.convert('RGB')\n",
    "\n",
    "    # Resize the image to 32x32 pixels\n",
    "    image = image.resize(resolution)\n",
    "\n",
    "    # Convert the image to a PyTorch tensor\n",
    "    if keep_alpha:\n",
    "        # If we're keeping the alpha channel, convert the image to a 4D tensor with shape (1, 4, 32, 32)\n",
    "        tensor = transforms.functional.to_tensor(image).unsqueeze(0)\n",
    "    else:\n",
    "        # If we're not keeping the alpha channel, convert the image to a 3D tensor with shape (1, 3, 32, 32)\n",
    "        tensor = transforms.functional.to_tensor(image).unsqueeze(0)[:, :3]\n",
    "\n",
    "    # Normalize the tensor if requested\n",
    "    if normalize:\n",
    "        if keep_alpha:\n",
    "            # If we're keeping the alpha channel, normalize using a mean and std for a 4D tensor\n",
    "            mean = torch.tensor([0.5, 0.5, 0.5, 0.5])\n",
    "            std = torch.tensor([0.5, 0.5, 0.5, 0.5])\n",
    "        else:\n",
    "            # If we're not keeping the alpha channel, normalize using a mean and std for a 3D tensor\n",
    "            mean = torch.tensor([0.5, 0.5, 0.5])\n",
    "            std = torch.tensor([0.5, 0.5, 0.5])\n",
    "        tensor = transforms.functional.normalize(tensor, mean=mean, std=std)\n",
    "\n",
    "    return tensor\n",
    "\n",
    "\n",
    "def preprocess_images_folder(folder_path, resolution=(32, 32)):\n",
    "    tensor_list = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            # Preprocess the image and append the tensor to the list\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            tensor = preprocess_image(image_path,\n",
    "                                      normalize=True,\n",
    "                                      keep_alpha=False,\n",
    "                                      resolution=resolution)\n",
    "            tensor_list.append(tensor)\n",
    "    # Stack the list of tensors into a single tensor\n",
    "    tensor_stack = torch.stack(tensor_list)\n",
    "    tensor_stack = tensor_stack.squeeze()  # remove the singleton dimension\n",
    "\n",
    "    return tensor_stack\n",
    "\n",
    "\n",
    "def create_train_loader(tensor_stack, batch_size=32, shuffle=True):\n",
    "    # Create a dataset from the tensor stack\n",
    "    dataset = TensorDataset(tensor_stack)\n",
    "\n",
    "    # Create a dataloader from the dataset\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n",
    "\n",
    "    return train_loader\n",
    "\n",
    "\n",
    "\n",
    "pokemon = preprocess_images_folder(\n",
    "    '/Users/juan-garassino/Code/juan-garassino/miniTransformer/miniTransformer/data/pokemon',\n",
    "    resolution=(32, 32))\n",
    "\n",
    "train_loader = create_train_loader(pokemon,\n",
    "                                                 batch_size=32,\n",
    "                                                 shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def display_images(folder_path, resolution):\n",
    "    # Get a list of all image file paths in the folder\n",
    "    image_paths = [\n",
    "        os.path.join(folder_path, f) for f in os.listdir(folder_path)\n",
    "        if f.endswith('.jpg') or f.endswith('.png')\n",
    "    ]\n",
    "\n",
    "    # Select 25 random images from the list\n",
    "    selected_images = random.sample(image_paths, 25)\n",
    "\n",
    "    # Set up the matplotlib figure with two subplots\n",
    "    fig, axs = plt.subplots(5, 10, figsize=(20, 10))\n",
    "\n",
    "    # Loop through each selected image, preprocess it, and display it\n",
    "    for i, image_path in enumerate(selected_images):\n",
    "        # Load the image using PIL\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Display the image in the original resolution\n",
    "        axs[i // 5, i % 5 * 2].imshow(image)\n",
    "        axs[i // 5, i % 5 * 2].set_title('Original Resolution')\n",
    "        axs[i // 5, i % 5 * 2].axis('off')\n",
    "\n",
    "        # Resize the image to the specified resolution\n",
    "        new_image = image.resize((resolution, resolution))\n",
    "\n",
    "        # Display the image in the new resolution\n",
    "        axs[i // 5, i % 5 * 2 + 1].imshow(new_image)\n",
    "        axs[i // 5,\n",
    "            i % 5 * 2 + 1].set_title(f'{resolution}x{resolution} Resolution')\n",
    "        axs[i // 5, i % 5 * 2 + 1].axis('off')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "display_images(\n",
    "    '/Users/juan-garassino/Code/juan-garassino/miniTransformer/miniTransformer/data/pokemon', 32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = nn.functional.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.up1 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.conv1 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.up3 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "        self.conv3 = nn.Conv2d(32, 3, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.up1(x)\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = self.up2(x)\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = self.up3(x)\n",
    "        x = nn.functional.relu(self.conv3(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder()\n",
    "\n",
    "encoded_pokemon = encoder(pokemon)\n",
    "\n",
    "encoded_pokemon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder(inputs).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the loss function (MSE loss)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer (Adam optimizer)\n",
    "lr = 0.001\n",
    "betas = (0.9, 0.999)\n",
    "eps = 1e-08\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=lr, betas=betas, eps=eps)\n",
    "\n",
    "# Train the autoencoder\n",
    "num_epochs = 10\n",
    "print_freq = 1  # Print loss every 10 iterations\n",
    "plot_freq = 1  # Plot original and reconstructed images every 50 iterations\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # Get the inputs\n",
    "        inputs = data[0]\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = autoencoder(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, inputs)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % print_freq == 0:\n",
    "            print('[Epoch %d, Iter %d/%d] Loss: %.6f' %\n",
    "                  (epoch + 1, i + 1, len(train_loader),\n",
    "                   running_loss / print_freq))\n",
    "            running_loss = 0.0\n",
    "\n",
    "        # Plot original and reconstructed images\n",
    "        if (i + 1) % plot_freq == 0:\n",
    "            fig, axes = plt.subplots(nrows=2,\n",
    "                                     ncols=5,\n",
    "                                     sharex=True,\n",
    "                                     sharey=True,\n",
    "                                     figsize=(12, 6))\n",
    "            inputs_np = inputs.cpu().detach().numpy()\n",
    "            outputs_np = outputs.cpu().detach().numpy()\n",
    "            for j in range(5):\n",
    "                axes[0][j].imshow(inputs_np[j].transpose(1, 2, 0))\n",
    "                axes[1][j].imshow(outputs_np[j].transpose(1, 2, 0))\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the loss function (MSE loss)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define the optimizer (Adam optimizer)\n",
    "lr = 0.001\n",
    "betas = (0.9, 0.999)\n",
    "eps = 1e-08\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=lr, betas=betas, eps=eps)\n",
    "\n",
    "# Train the autoencoder\n",
    "num_epochs = 2\n",
    "print_freq = 1  # Print loss every 1 iterations\n",
    "plot_freq = 5  # Plot original and reconstructed images every 5 iterations\n",
    "\n",
    "losses = []  # to store loss values at each iteration\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # Get the inputs\n",
    "        inputs = data[0]\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = autoencoder(inputs)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, inputs)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "        if (i + 1) % print_freq == 0:\n",
    "            print('[Epoch %d, Iter %d/%d] Loss: %.6f' %\n",
    "                  (epoch + 1, i + 1, len(train_loader),\n",
    "                   running_loss / print_freq))\n",
    "            losses.append(running_loss / print_freq)  # store the loss value\n",
    "            running_loss = 0.0\n",
    "\n",
    "        # Plot original and reconstructed images\n",
    "        if (i + 1) % plot_freq == 0:\n",
    "            fig, axes = plt.subplots(nrows=2,\n",
    "                                     ncols=5,\n",
    "                                     sharex=True,\n",
    "                                     sharey=True,\n",
    "                                     figsize=(12, 6))\n",
    "            inputs_np = inputs.cpu().detach().numpy()\n",
    "            outputs_np = outputs.cpu().detach().numpy()\n",
    "            for j in range(5):\n",
    "                axes[0][j].imshow(inputs_np[j].transpose(1, 2, 0))\n",
    "                axes[1][j].imshow(outputs_np[j].transpose(1, 2, 0))\n",
    "            plt.show()\n",
    "\n",
    "# plot the loss values\n",
    "plt.plot(losses)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "\n",
    "def make_noise_schedule(num_steps, noise_schedule_type='linear'):\n",
    "    if noise_schedule_type == 'linear':\n",
    "        # Linear noise schedule: start with high noise and decrease it linearly\n",
    "        return [math.sqrt(i / (num_steps - 1)) for i in range(num_steps)]\n",
    "    elif noise_schedule_type == 'cosine':\n",
    "        # Cosine noise schedule: start with high noise and decrease it using a cosine function\n",
    "        return [\n",
    "            math.sqrt(0.5 * (1 + math.cos(math.pi * i / num_steps)))\n",
    "            for i in range(num_steps)\n",
    "        ]\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown noise schedule type: {noise_schedule_type}\")\n",
    "\n",
    "\n",
    "noise_schedule = make_noise_schedule(1000, noise_schedule_type='linear')\n",
    "\n",
    "def guided_diffusion_step(latent, diffusion_steps_left, noise_schedule,\n",
    "                          denoise_fn):\n",
    "    # Generate random noise with the same shape as the latent representation\n",
    "    noise = torch.randn_like(latent) * noise_schedule[diffusion_steps_left - 1]\n",
    "\n",
    "    # Mix the noise with the latent representation\n",
    "    mixed_latent = latent + noise\n",
    "\n",
    "    # Perform the diffusion process by running the mixed latent representation through the denoise function\n",
    "    denoised_latent = denoise_fn(mixed_latent, diffusion_steps_left - 1)\n",
    "\n",
    "    return denoised_latent\n",
    "\n",
    "\n",
    "def guided_diffusion(latent, noise_schedule, denoise_fn, num_steps=1000):\n",
    "    for i in range(num_steps):\n",
    "        latent = guided_diffusion_step(latent, num_steps - i, noise_schedule,\n",
    "                                       denoise_fn)\n",
    "    return latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_schedule = make_noise_schedule(1000, noise_schedule_type='linear')\n",
    "\n",
    "noise_schedule[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Denoise(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Denoise, self).__init__()\n",
    "\n",
    "        # Define a small U-Net architecture with 2 downsample blocks and 2 upsample blocks\n",
    "        self.down1 = nn.Conv2d(128, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.down2 = nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.up1 = nn.ConvTranspose2d(64,\n",
    "                                      64,\n",
    "                                      kernel_size=4,\n",
    "                                      stride=2,\n",
    "                                      padding=1)\n",
    "        self.up2 = nn.ConvTranspose2d(64,\n",
    "                                      128,\n",
    "                                      kernel_size=4,\n",
    "                                      stride=2,\n",
    "                                      padding=1)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # Apply the downsample blocks\n",
    "        x = self.down1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.down2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Apply the upsample blocks with noise injection\n",
    "        noise = torch.randn_like(x) * math.sqrt(t)\n",
    "        x = self.up1(x + noise)\n",
    "        x = F.relu(x)\n",
    "        noise = torch.randn_like(x) * math.sqrt(t)\n",
    "        x = self.up2(x + noise)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_latent(latent):\n",
    "    # Define the decoder network\n",
    "    decoder = nn.Sequential(\n",
    "        nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.ConvTranspose2d(64, 64, kernel_size=4, stride=2, padding=1),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),\n",
    "        nn.Sigmoid())\n",
    "\n",
    "    # Pass the latent representation through the decoder network\n",
    "    output = decoder(latent)\n",
    "\n",
    "    # Reshape the output to the desired image shape\n",
    "    output = output.view(1, 3, 32, 32)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_latent(latent):\n",
    "    # Instantiate the decoder network\n",
    "    decoder = Decoder()\n",
    "\n",
    "    # Pass the latent representation through the decoder network\n",
    "    output = decoder(latent)\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(output):\n",
    "    # Convert the output tensor to a NumPy array\n",
    "    output = output.detach().cpu().numpy()\n",
    "\n",
    "    # Convert the pixel values from [0, 1] to [0, 255] and round to the nearest integer\n",
    "    output = np.round(output * 255).astype(np.uint8)\n",
    "\n",
    "    # Transpose the tensor from (1, 3, 32, 32) to (32, 32, 3)\n",
    "    output = np.transpose(output, (0, 2, 3, 1))\n",
    "\n",
    "    # Display the output as an image\n",
    "    plt.imshow(output.squeeze())\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(image_path):\n",
    "    # Load the input image\n",
    "    input_image = load_image(image_path)\n",
    "\n",
    "    # Preprocess the input image\n",
    "    input_tensor = preprocess(input_image)\n",
    "\n",
    "    # Encode the input image into a latent representation\n",
    "    latent = encode_input(input_tensor)\n",
    "\n",
    "    # Apply guided diffusion to the latent representation\n",
    "    guided_latent = guided_diffusion(latent)\n",
    "\n",
    "    # Decode the final latent representation into an output image\n",
    "    output_tensor = decode_latent(guided_latent)\n",
    "\n",
    "    # Postprocess the output image and display it\n",
    "    postprocess(output_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 64\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Define the learning rate\n",
    "learning_rate = 0.0002\n",
    "\n",
    "# Define the device to use for computation\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create the dataset and data loader\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Resize((32, 32)),\n",
    "     transforms.ToTensor()])\n",
    "dataset = CIFAR10(root='./data',\n",
    "                  train=True,\n",
    "                  download=True,\n",
    "                  transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Create the model and move it to the device\n",
    "model = PixelArtGuidedDiffusion().to(device)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Loop over the epochs\n",
    "for epoch in range(num_epochs):\n",
    "    # Loop over the batches in the data loader\n",
    "    for batch_idx, (data, _) in enumerate(loader):\n",
    "        # Move the input data to the device\n",
    "        data = data.to(device)\n",
    "\n",
    "        # Perform the forward pass\n",
    "        input_tensor = preprocess(data)\n",
    "        latent = encode_input(input_tensor)\n",
    "        guided_latent = guided_diffusion(latent)\n",
    "        output_tensor = decode_latent(guided_latent)\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = loss_fn(output_tensor, input_tensor)\n",
    "\n",
    "        # Zero the gradients, perform the backward pass, and update the weights\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Generate a new test picture every epoch to monitor the training\n",
    "        if batch_idx == 0:\n",
    "            test_input = load_image('./test_image.png')\n",
    "            test_input_tensor = preprocess(test_input)\n",
    "            test_latent = encode_input(test_input_tensor)\n",
    "            test_guided_latent = guided_diffusion(test_latent)\n",
    "            test_output_tensor = decode_latent(test_guided_latent)\n",
    "            postprocess(test_output_tensor)\n",
    "\n",
    "    # Print the loss at the end of each epoch\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "miniTransformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d2eb4c4e65757a2388ec457461da5e8a5ba758a2d79b2cc525712e4186b71fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
