# miniTransformer

miniTransformer is a small-scale implementation of the Transformer model in Python, designed to be lightweight and easy to understand. This project includes components for training a simplified Transformer model, creating a custom tokenizer, visualizing attention weights, and generating text after training.

## Features

- **Transformer Model**: Implements a simplified version of the Transformer architecture, including self-attention layers and feed-forward networks.
- **Custom Tokenizer**: Provides functionality to create a custom tokenizer for encoding and decoding text data.
- **Visualization**: Allows visualization of the attention weights for query (Q), key (K), and value (V) matrices during training.
- **Text Generation**: Generates text using the trained Transformer model.
- **Google Colab Notebook**: Includes a Google Colab notebook for running the project in a cloud-based environment.
